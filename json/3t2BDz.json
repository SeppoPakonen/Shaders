{"ver": "0.1", "info": {"id": "3t2BDz", "date": "1598712556", "viewed": 547, "name": "WoS approx. lighting with SDFs", "username": "toomuchvoltage", "description": "Walk-on-spheres approximate lighting with SDF luminares using Sawhney & Crane 2020 in http://www.cs.cmu.edu/~kmcrane/Projects/MonteCarloGeometryProcessing/paper.pdf. It has bias but converges rather quickly.", "likes": 7, "published": 3, "flags": 32, "tags": ["walk"], "requires": ["texture", "texturebuf", "imagebuf"]}, "renderpass": [{"inputs": [{"id": "4dXGR8", "filepath": "/media/previz/buffer00.png", "previewfilepath": "/media/previz/buffer00.png", "type": "buffer", "channel": 0, "sampler": {"filter": "linear", "wrap": "clamp", "vflip": "true", "srgb": "false", "internal": "byte"}, "published": 1}], "outputs": [{"id": "4dfGRr", "channel": 0}], "code": "/***********************************************************\n\n   I've been itching to try this out ever since I saw this: http://www.cs.cmu.edu/~kmcrane/Projects/MonteCarloGeometryProcessing/paper.pdf\n   I know this is for geometry processing but I couldn't help myself... wanted to see how this would actually turn out in utility to direct lighting.\n   It has bias because we don't have the exact projected sampling area but converges rather quickly.\n   All your sdf and value noises are belong to iq ;) : https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm\n\n   Covered under the MIT license:\n\n   Copyright (c) 2020 TooMuchVoltage Software Inc.\n\n   Permission is hereby granted, free of charge, to any person obtaining a copy\n   of this software and associated documentation files (the \"Software\"), to deal\n   in the Software without restriction, including without limitation the rights\n   to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n   copies of the Software, and to permit persons to whom the Software is\n   furnished to do so, subject to the following conditions:\n\n   The above copyright notice and this permission notice shall be included in all\n   copies or substantial portions of the Software.\n\n   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n   AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n   OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n   SOFTWARE.\n\n\n   Hit me up! :)\n   Twitter: twitter.com/toomuchvoltage\n   Facebook: fb.com/toomuchvoltage\n   YouTube: youtube.com/toomuchvoltage\n   Mastodon: https://mastodon.gamedev.place/@toomuchvoltage\n   Website: www.toomuchvoltage.com\n\n************************************************************/\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uvRaw = fragCoord/iResolution.xy;\n    vec4 fetchMC = texture(iChannel0, uvRaw);\n    fragColor = vec4 (fetchMC.rgb/fetchMC.a, 1.0);\n}", "name": "Image", "description": "", "type": "image"}, {"inputs": [{"id": "4dXGR8", "filepath": "/media/previz/buffer00.png", "previewfilepath": "/media/previz/buffer00.png", "type": "buffer", "channel": 0, "sampler": {"filter": "linear", "wrap": "clamp", "vflip": "true", "srgb": "false", "internal": "byte"}, "published": 1}, {"id": "XsBSR3", "filepath": "/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png", "previewfilepath": "/media/ap/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png", "type": "texture", "channel": 1, "sampler": {"filter": "nearest", "wrap": "repeat", "vflip": "true", "srgb": "false", "internal": "byte"}, "published": 1}], "outputs": [{"id": "4dXGR8", "channel": 0}], "code": "/***********************************************************\n\n   I've been itching to try this out ever since I saw this: http://www.cs.cmu.edu/~kmcrane/Projects/MonteCarloGeometryProcessing/paper.pdf\n   I know this is for geometry processing but I couldn't help myself... wanted to see how this would actually turn out in utility to direct lighting.\n   It has bias because we don't have the exact projected sampling area but converges rather quickly.\n   All your sdf and value noises are belong to iq ;) : https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm\n\n   Covered under the MIT license:\n\n   Copyright (c) 2020 TooMuchVoltage Software Inc.\n\n   Permission is hereby granted, free of charge, to any person obtaining a copy\n   of this software and associated documentation files (the \"Software\"), to deal\n   in the Software without restriction, including without limitation the rights\n   to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n   copies of the Software, and to permit persons to whom the Software is\n   furnished to do so, subject to the following conditions:\n\n   The above copyright notice and this permission notice shall be included in all\n   copies or substantial portions of the Software.\n\n   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n   AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n   OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n   SOFTWARE.\n\n\n   Hit me up! :)\n   Twitter: twitter.com/toomuchvoltage\n   Facebook: fb.com/toomuchvoltage\n   YouTube: youtube.com/toomuchvoltage\n   Mastodon: https://mastodon.gamedev.place/@toomuchvoltage\n   Website: www.toomuchvoltage.com\n\n************************************************************/\n\n\n#define DRAW_DISTANCE 100.0\n#define M_PI 3.1415926535\n\n#define BSDF_TRACING (uv.x > 0.0)\n\n// *******************************************************\n// Change sceneLum(vec3 p) to try any of them out\n// They converge faster! though with bias. This is because we don't have the exact projected sampling area.\n// This could be useful for video games where you may not have HW raytracing but you can get direct volume lighting.\n// *******************************************************\n\nfloat sceneLumSphere (vec3 p) // Sphere\n{\n    return length(p) - 0.5;\n}\n\nfloat sceneLumBox (vec3 p) // Box\n{\n    vec3 q = abs(p) - vec3 (0.2);\n    return length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0);\n}\n\nfloat sceneLumTorus (vec3 p) // Capped torus\n{\n    float ra = 1.0;\n    float rb = 0.1;\n    vec2 sc = vec2 (1.0, 0.025);\n    p.x = abs(p.x);\n    float k = (sc.y*p.x>sc.x*p.y) ? dot(p.xy,sc) : length(p.xy);\n    return sqrt( dot(p,p) + ra*ra - 2.0*ra*k ) - rb;\n}\n\nfloat sceneLumLink(vec3 p) // Link\n{\n    float le = 0.5;\n    float r1 = 0.5;\n    float r2 = 0.05;\n    vec3 q = vec3( p.x, max(abs(p.y)-le,0.0), p.z );\n    return length(vec2(length(q.xy)-r1,q.z)) - r2;\n}\n\nfloat sdOctahedron(vec3 p) // Octahedron\n{\n    float s = 0.5;\n    p = abs(p);\n    float m = p.x+p.y+p.z-s;\n    vec3 q;\n    if( 3.0*p.x < m ) q = p.xyz;\n    else if( 3.0*p.y < m ) q = p.yzx;\n        else if( 3.0*p.z < m ) q = p.zxy;\n            else return m*0.57735027;\n\n            float k = clamp(0.5*(q.z-q.y+s),0.0,s); \n        return length(vec3(q.x,q.y-s+k,q.z-k)); \n}\n\nfloat sceneLum(vec3 p)\n{\n    return sceneLumSphere (p); // <--- Change this to try different ones...\n}\n\n// *******************************************************\n// *******************************************************\n// *******************************************************\n\nfloat scene (vec3 p, out float mat)\n{\n    mat = 0.0;\n    float walls = p.y + 1.0;\n    walls = min (walls, -p.z + 1.0);\n    \n    float lamp = sceneLum(p);\n    \n    float sceneSDF = min (lamp, walls);\n    \n    if ( sceneSDF == lamp ) mat = 1.0;\n    else mat = 0.0;\n\n    return sceneSDF;\n}\n\nvec3 hash(vec3 p)  // replace this by something better\n{\n\tp = 50.0*fract( p*0.3183099 + vec3(0.71,0.113,0.419));\n\tfloat xVal = -1.0+2.0*fract( p.x*p.y*(p.x+p.y) );\n\tfloat yVal = -1.0+2.0*fract( p.x*p.z*(p.x+p.z) );\n\tfloat zVal = -1.0+2.0*fract( p.z*p.y*(p.z+p.y) );\n    return vec3(xVal, yVal, zVal);\n}\n\nvec3 randOnHemi (vec2 randVar, vec3 surfNorm)\n{\n    float phi = 2.0*M_PI*randVar.x;\n    float theta = acos (1.0 - randVar.y);\n    \n    vec3 tanVec = normalize (cross (surfNorm + vec3 (0.1), surfNorm));\n    vec3 biTanVec = cross (tanVec, surfNorm);\n    \n    vec3 x = sin(theta)*cos(phi)*tanVec;\n    vec3 y = sin(theta)*sin(phi)*biTanVec;\n    vec3 z = cos(theta)*surfNorm;\n    return normalize (x + y + z);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uvRaw = fragCoord/iResolution.xy;\n    vec2 uv = uvRaw * 2.0 - 1.0;\n    uv.y *= iResolution.y/iResolution.x;\n    \n    vec4 mouseInfo = iMouse / iResolution.xxxx;\n    \n    vec3 curEye = vec3 (cos(mouseInfo.x * 2.0 - M_PI * 0.5), mouseInfo.y * 3.0, sin(mouseInfo.x * 2.0 - M_PI * 0.5)) * 2.0;\n    vec3 sampleLook = normalize (-curEye);\n    \n    vec3 side = cross (vec3 (0.0, -1.0, 0.0), sampleLook);\n    vec3 up = cross (side, sampleLook);\n    if ( dot (up, vec3 (0.0, 1.0, 0.0)) < 0.0 ) up = -up;\n    \n    const float drawDistSq = DRAW_DISTANCE*DRAW_DISTANCE;\n    vec3 sampleDir = normalize (sampleLook + side * uv.x + up * uv.y);\n    vec3 samplePt = curEye + sampleDir;\n    vec3 colorAccum = vec3 (1.0);\n\n    samplePt = curEye + sampleDir;\n    bool samplingLight = false;\n    vec3 hitNorm;\n    vec3 hitPoint;\n    float mcMode = 0.0;\n    float jj = 0.0;\n\n    for (jj = 0.0; jj != 120.0; jj += 1.0) // Sometimes you just gotta give...\n    {\n        vec3 samplePtToEye0 = samplePt - curEye;\n        float distToSamplePtSq0 = dot (samplePtToEye0,samplePtToEye0);\n        float sceneMat;\n        float curDist = scene (samplePt, sceneMat);\n        if (abs(curDist) < 0.01 )\n        {\n            if ( sceneMat == 1.0 )\n            {\n                if ( mcMode == 0.0 )\n                {\n\t                colorAccum = vec3 (1.0, 1.0, 1.0);\n    \t            break;\n                }\n                else\n                {\n                    vec3 E = vec3 (4.0);\n\t\t\t\t\tif ( BSDF_TRACING )\n                    \tcolorAccum *= 2.0 * max (dot (hitNorm, normalize (samplePt - hitPoint)), 0.0) * E;\n                    else\n                    {\n                        float sceneMatTmp;\n                        vec3 lightNorm;\n                        lightNorm.x = scene(samplePt + vec3(0.001, 0.0, 0.0), sceneMatTmp) - scene(samplePt - vec3(0.001, 0.0, 0.0), sceneMatTmp);\n                        lightNorm.y = scene(samplePt + vec3(0.0, 0.001, 0.0), sceneMatTmp) - scene(samplePt - vec3(0.0, 0.001, 0.0), sceneMatTmp);\n                        lightNorm.z = scene(samplePt + vec3(0.0, 0.0, 0.001), sceneMatTmp) - scene(samplePt - vec3(0.0, 0.0, 0.001), sceneMatTmp);\n                        lightNorm = normalize (lightNorm);\n                        vec3 lightSegment = samplePt - hitPoint;\n                        vec3 Lo = normalize (lightSegment);\n                        float NddotLo = abs (dot (hitNorm, Lo));\n                        float LidotNl = abs (dot (lightNorm, -Lo));\n                        float distSq = dot (lightSegment, lightSegment);\n                        float GeomTerm = (NddotLo * LidotNl) / distSq;\n                        colorAccum *= GeomTerm * 0.75 * E; // We don't have |A| so just make stuff up...\n                    }\n                    break;\n                }\n            }\n            else\n            {\n                if ( mcMode == 0.0 )\n                {\n                    float sceneMatTmp;\n                    hitNorm.x = scene(samplePt + vec3(0.001, 0.0, 0.0), sceneMatTmp) - scene(samplePt - vec3(0.001, 0.0, 0.0), sceneMatTmp);\n                    hitNorm.y = scene(samplePt + vec3(0.0, 0.001, 0.0), sceneMatTmp) - scene(samplePt - vec3(0.0, 0.001, 0.0), sceneMatTmp);\n                    hitNorm.z = scene(samplePt + vec3(0.0, 0.0, 0.001), sceneMatTmp) - scene(samplePt - vec3(0.0, 0.0, 0.001), sceneMatTmp);\n                    hitNorm = normalize (hitNorm);\n                    hitPoint = samplePt;\n\t\t\t\t\tif ( BSDF_TRACING )\n                    {\n                        vec2 randVar = (hash (samplePt * 3.0 + vec3(iTime * 3.0)).xz + vec2 (1.0)) * 0.5;\n                        sampleDir = randOnHemi (randVar, hitNorm);\n                        samplePt += hitNorm * 0.01;\n                    }\n                    mcMode = 1.0;\n                }\n                else\n                {\n                    colorAccum = vec3 (0.0);\n                    break;\n                }\n            }\n        }\n\t\tif ( !BSDF_TRACING )\n        {\n            if ( mcMode == 1.0 ) // Use Montecarlo PDE method by Sawhney & Crane\n            {\n                sampleDir = normalize (textureLod (iChannel1, samplePt.xz * 3.0 + iTime * samplePt.zy * 3.0, 0.0).rgb * 2.0 - 1.0);\n                float curDistToLum = sceneLum(samplePt);\n                samplePt += curDistToLum*sampleDir;\n            }\n            else\n\t        \tsamplePt += curDist*sampleDir;\n        }\n        else\n\t\t\tsamplePt += curDist*sampleDir;\n        vec3 samplePtToEye = samplePt - curEye;\n        if ( dot (samplePtToEye,samplePtToEye) > drawDistSq )\n        {\n            colorAccum = vec3 (0.0);\n            break ;\n        }\n    }\n    \n    if ( jj == 120.0 ) colorAccum = vec3 (0.0);\n\n    vec4 bufA = texture(iChannel0, uvRaw);\n    if ( mouseInfo.z > 0.0 )\n        bufA = vec4 (colorAccum, 1.0);\n    else\n        bufA += vec4 (colorAccum, 1.0);\n    fragColor = bufA;\n}", "name": "Buffer A", "description": "", "type": "buffer"}]}